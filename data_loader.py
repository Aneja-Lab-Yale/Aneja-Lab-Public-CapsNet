# CapsNet Project
# Data loader for 3D CapsNet and 3D U-Net models.
# contains AdniData class that generates input/output paris for training.
# Aneja Lab | Yale School of Medicine
# Developed by Arman Avesta, MD
# Created (3/30/21)
# Updated (3/15/22)

# ----------------------------------------------------- Imports ----------------------------------------------------

import torch
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import os
import pandas as pd
from dipy.io.image import load_nifti, save_nifti
import numpy as np


# ----------------------------------------------- AdniDataset class ------------------------------------------------

class AdniDataset(Dataset):
    """
    This class generates input/target paris for pytorch data loader:
        - Inputs: masked brain MRIs
        - Targets: FreeSurfer segmentations: aparc+aseg.mgz files

    ADNI (Alzheimer's Disease Neuroimaging Initiative) is a data-sharing platform managed by
    LONI (Laboatory of NeuroIMaging), that contains thousands of brain MRIs as well as
    post-processed images such as brain segmentations (using FreeSurfer and MAPER).
    More info: http://adni.loni.usc.edu/
    """

    def __init__(self, image_list, mask_list, maskcode,
                 crop=None,
                 cropshift=(0, 0, 0),
                 transforms=None,
                 testmode=False):
        """
        Inputs:
            - image_list: list of paths (type: strings list) to input images (e.g. brain MRI).
            - mask_list: list of paths (type: strings list) to output images (e.g. aparc+aseg.mgz files with
                multi-class brain segmentations)
            - crop: (x, y, z) of cropped volume: x is left-right, y is posterior-anterior, and z is inferior-superior
                    OR
                    x: just one integer --> image will be cropped to (x, x, x).
                    Note that (x, y, z) here is set using standard radiology system ('L','A','S').
            - cropshift: (x, y, z) to shift the crop box; positive and negative values repsectively move the
                crop box towards positive and negative directions of ('L','A','S') coordinate system.
            - maskcode: numerical code of the target structure in aparc+aseg.mgz file. For instance, maskcode for
                third ventricle is 14. You can find these codes by opening an aparc+aseg.mgz in FreeView.
                If the target is a binary mask generated by FreeSurfer (e.g. a hippocampus binary mask),
                maskcode=128, since FreeSurfer uses (0, 128) for binary masks.
            - transform: list of transform(s) to be done on the image
            - testmode: if this is set as True, the dataloader additionally corrects affine transforms for
                the cropped image/mask paris.
                In this mode, dataloader not only returns the image/mask paris, but also corrected
                affine transforms for cropped images and paths to the input images
                (to be used for saving predictions as nifti files).

        Outputs if not in test mode:
            - image: cropped image volume
            - mask: cropped mask volume
        Outputs if in test mode:
            - image: cropped image volume
            - mask: cropped mask volume
            - shape: np.array([depth, height, width, 1])
            - crop_coords: coordinates of the cropped volume:
                np.array([[xstart, xstop],
                          [zstart, zstop],
                          [ystart, ystop]])
            - affine: affine transform from the ceneter of the scanner to the loaded MRI volume.
                This info is loaded from the NIfTI header.
            - mask_path: path to the mask NIfTI file.
        """
        assert len(image_list) == len(mask_list)
        self.image_list = image_list
        self.mask_list = mask_list

        self.maskcode = maskcode

        # if crop/cropshift are int e.g. 64 --> turn them into (64, 64, 64)
        self.crop = (crop, crop, crop) if isinstance(crop, int) else crop
        self.cropshift = (cropshift, cropshift, cropshift) if isinstance(cropshift, int) else cropshift
        self.transforms = transforms
        self.testmode = testmode

    # ........................................................................................................

    def __len__(self):
        return len(self.image_list)


    def __getitem__(self, index):
        image_path = self.image_list[index]
        mask_path = self.mask_list[index]

        image, affine = load_nifti(image_path)
        mask, affine2 = load_nifti(mask_path)

        assert image.shape == mask.shape
        assert (affine == affine2).all()

        shape = np.array(image.shape)

        if self.crop is not None:
            image, crop_coords = self.crop_image(image)
            mask, crop_coords = self.crop_image(mask)
        else:
            crop_coords = shape

        if self.transforms is not None:
            image, mask = self.transforms(image, mask)

        # Extract binary mask from aparc+aseg.mgz:
        mask = self.generate_binary_mask(mask)
        # Add channel dimension --> change dtype to float32
        image = np.expand_dims(image, axis=0).astype('float32')
        mask = np.expand_dims(mask, axis=0).astype('float32')

        if self.testmode:
            return image, mask, shape, crop_coords, affine, mask_path

        return image, mask

    # ........................................................................................................

    def crop_image(self, image):
        (x, y, z) = image.shape  # this works if inputs & outputs are in ('L','A','S') coordinate system
        xcrop, ycrop, zcrop = self.crop[0], self.crop[1], self.crop[2]
        xshift, yshift, zshift = self.cropshift[0], self.cropshift[1], self.cropshift[2]  # ('L','A','S') system

        xmid, ymid, zmid = x // 2, y // 2, z // 2
        xdiff, ydiff, zdiff = xcrop // 2, ycrop // 2, zcrop // 2

        xstart, ystart, zstart = xmid - xdiff + xshift, ymid - ydiff + yshift, zmid - zdiff + zshift
        xstop, ystop, zstop = xmid + xdiff + xshift, ymid + ydiff + yshift, zmid + zdiff + zshift

        if xstart < 0:
            xstop -= xstart
            xstart = 0
        if ystart < 0:
            ystop -= ystart
            ystart = 0
        if zstart < 0:
            zstop -= zstart
            zstart = 0
        if xstop > x:
            xstart -= xstop - x
            xstop = x
        if ystop > y:
            ystart -= ystop - y
            ystop = y
        if zstop > z:
            zstart -= zstop - z
            zstop = z
        assert (xstart >= 0) and (ystart >= 0) and (zstart >= 0) and (xstop <= x) and (ystop <= y) and (zstop <= z)

        cropped_image = image[xstart:xstop, ystart:ystop, zstart:zstop]     # ('L','A','S') coordinate system
        crop_coords = np.array([[xstart, xstop],                            # ('L','A','S') coordinate system
                                [ystart, ystop],
                                [zstart, zstop]])

        return cropped_image, crop_coords

    # ........................................................................................................

    def generate_binary_mask(self, mask):
        binary_mask = np.zeros_like(mask)
        binary_mask[mask == self.maskcode] = 1
        return binary_mask



# ------------------------------------------------- Helper functions ------------------ooo-----------------------------

def make_image_list(path_to_images_csv):
    images_df = pd.read_csv(path_to_images_csv, header=None)
    images_list = list(images_df.iloc[:, 0])
    return images_list



# ------------------------------------------- AdniDataset code  testing -----------------------------------------------

if __name__ == "__main__":
    from pre_processing.mri_slicer import imshow

    np.set_printoptions(precision=1, suppress=True)
    torch.set_printoptions(precision=1, sci_mode=False)

    #######################################################

    project_root = '/Users/arman/projects/capsnet'
    images_csv = 'data/datasets_local/train_inputs.csv'
    masks_csv = 'data/datasets_local/train_outputs.csv'

    images_path = os.path.join(project_root, images_csv)
    masks_path = os.path.join(project_root, masks_csv)

    image_list = make_image_list(images_path)
    mask_list = make_image_list(masks_path)

    adni = AdniDataset(image_list, mask_list, maskcode=14, crop=100, testmode=True)
    dataloader = DataLoader(dataset=adni, batch_size=40, shuffle=True)
    itr = iter(dataloader)

    try:
        images, masks, shapes, crops_coords, affines, masks_paths = next(itr)
    except StopIteration:
        itr = iter(dataloader)
        images, masks, shapes, crops_coords, affines, masks_paths = next(itr)

    print(f'images --> shape: {images.shape}; data type: {images.dtype}; min: {images.min()}; max: {images.max()}')
    print(f'masks --> shape: {masks.shape}; data type: {masks.dtype}; unique values: {masks.unique()}')
    print(f'affines --> shape: {affines.shape}; data type: {affines.dtype}; values: \n{affines}')
    print(f'crops_coords --> shape: {crops_coords.shape}; data type: {crops_coords.dtype}; values: \n{crops_coords}')
    print(f'shapes --> shape: {shapes.shape}; data type: {shapes.dtype}; values: \n{shapes}')
    print(f'paths --> length: {len(masks_paths)}; values: {masks_paths}')

    imshow(images)
    imshow(masks)
